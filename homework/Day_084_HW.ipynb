{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "# 不需使用 GPU, 將 GPU 設定為 \"無\"\n",
    "# 使用第一張 GPU 卡\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \" 0 \"\n",
    "# 只使用 60% 的 GPU 記憶體\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "# 設定 Keras 使用的 TensorFlow Session\n",
    "tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    # 資料前處理 - 標準化\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        # 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        # 用np_utils裡的to_categorical來做one-hot encoding的轉換：\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], l2_ratio=1e-4, drp_ratio=0.2):\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\",\n",
    "                                   kernel_regularizer=l2(l2_ratio),\n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = Dropout(drp_ratio)(x) # 隨機在一次update中，忽略了20%的neurons間的connection\n",
    "            x = BatchNormalization()(x) # 加入Batch Normalization，能夠將每一層的輸入/輸出做正規化\n",
    "            '''\n",
    "            參數:\n",
    "            units=n_units: 建立有n_units個神經元的隱藏層\n",
    "            kernel_regularizer: 權重(W)正規化(或稱 正則項)函數，作用是對權重矩陣加上懲罰性函數(Penalty)，以防止過度擬合(overfit)，參見 regularizer。\n",
    "            activation='relu': 使用relu為激活函數\n",
    "            '''\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\",\n",
    "                                   kernel_regularizer=l2(l2_ratio),\n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = Dropout(drp_ratio)(x) # 隨機在一次update中，忽略了25%的neurons間的connection\n",
    "            x = BatchNormalization()(x) # 加入Batch Normalization，能夠將每一層的輸入/輸出做正規化\n",
    "            '''\n",
    "            參數:\n",
    "            units=n_units: 建立有n_units個神經元的隱藏層\n",
    "            kernel_regularizer: 權重(W)正規化(或稱 正則項)函數，作用是對權重矩陣加上懲罰性函數(Penalty)，以防止過度擬合(overfit)，參見 regularizer。\n",
    "            activation='relu': 使用relu為激活函數\n",
    "            '''\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = 1e-3   # 學習率\n",
    "EPOCHS = 30 # 訓練30週期，訓練集所有樣本（數據、記錄）參與訓練一次爲一個週期\n",
    "BATCH_SIZE = [2, 16, 32, 128, 256]# 訓練時每個批次的樣本數。訓練樣本數/批次樣本數 = 批次數（每個週期）\n",
    "MOMENTUM = 0.95 #動量\n",
    "L2_EXP = [1e-2, 1e-4, 1e-8, 1e-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Regulizer = 0.010000\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 10.3793 - accuracy: 0.1335 - val_loss: 2.9826 - val_accuracy: 0.1804\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.9726 - accuracy: 0.1358 - val_loss: 2.8073 - val_accuracy: 0.1741\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.9445 - accuracy: 0.1381 - val_loss: 2.8010 - val_accuracy: 0.1775\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.9764 - accuracy: 0.1400 - val_loss: 3.0208 - val_accuracy: 0.1974\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 3.1425 - accuracy: 0.1390 - val_loss: 2.8153 - val_accuracy: 0.2190\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.8935 - accuracy: 0.1351 - val_loss: 2.7619 - val_accuracy: 0.1748\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 3.1564 - accuracy: 0.1340 - val_loss: 2.9939 - val_accuracy: 0.1725\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 3.2643 - accuracy: 0.1338 - val_loss: 3.3763 - val_accuracy: 0.1454\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 3.2170 - accuracy: 0.1340 - val_loss: 2.9932 - val_accuracy: 0.1751\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 3.2794 - accuracy: 0.1328 - val_loss: 3.6188 - val_accuracy: 0.1187\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 3.8327 - accuracy: 0.1342 - val_loss: 2.9441 - val_accuracy: 0.1687\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 3.1280 - accuracy: 0.1293 - val_loss: 2.7902 - val_accuracy: 0.1515\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 3.9707 - accuracy: 0.1238 - val_loss: 4.0328 - val_accuracy: 0.1148\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 3.4411 - accuracy: 0.1209 - val_loss: 2.8075 - val_accuracy: 0.1417\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 3.7399 - accuracy: 0.1208 - val_loss: 3.9917 - val_accuracy: 0.1337\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 4.6235 - accuracy: 0.1191 - val_loss: 5.1856 - val_accuracy: 0.1962\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 4.3104 - accuracy: 0.1181 - val_loss: 3.2099 - val_accuracy: 0.1127\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.8894 - accuracy: 0.1117 - val_loss: 2.3351 - val_accuracy: 0.1000\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.3069 - accuracy: 0.1002 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.3051 - accuracy: 0.0994 - val_loss: 2.3057 - val_accuracy: 0.1000\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 2.3051 - accuracy: 0.0992 - val_loss: 2.3055 - val_accuracy: 0.1000\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.3049 - accuracy: 0.0972 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.3050 - accuracy: 0.0995 - val_loss: 2.3049 - val_accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.3049 - accuracy: 0.0995 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 167s 3ms/step - loss: 2.3047 - accuracy: 0.0996 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.3047 - accuracy: 0.1011 - val_loss: 2.3051 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.3051 - accuracy: 0.0979 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.3050 - accuracy: 0.0985 - val_loss: 2.3052 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.3049 - accuracy: 0.1007 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.3048 - accuracy: 0.1029 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Experiment with Regulizer = 0.010000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 7.4434 - accuracy: 0.2567 - val_loss: 3.5691 - val_accuracy: 0.2049\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.6037 - accuracy: 0.2456 - val_loss: 2.1958 - val_accuracy: 0.2819\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.1594 - accuracy: 0.2418 - val_loss: 2.1524 - val_accuracy: 0.2198\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.1028 - accuracy: 0.2404 - val_loss: 2.0512 - val_accuracy: 0.2808\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.1683 - accuracy: 0.1976 - val_loss: 2.1909 - val_accuracy: 0.1911\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 2.2495 - accuracy: 0.1858 - val_loss: 2.1807 - val_accuracy: 0.1953\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.1593 - accuracy: 0.1992 - val_loss: 2.1380 - val_accuracy: 0.2192\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.0982 - accuracy: 0.2365 - val_loss: 2.0468 - val_accuracy: 0.2264\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.1170 - accuracy: 0.2158 - val_loss: 2.0477 - val_accuracy: 0.2675\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.1405 - accuracy: 0.1982 - val_loss: 2.1285 - val_accuracy: 0.1912\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 2.1417 - accuracy: 0.1921 - val_loss: 2.3980 - val_accuracy: 0.1333\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 2.1615 - accuracy: 0.2027 - val_loss: 2.1822 - val_accuracy: 0.1989\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.1320 - accuracy: 0.2064 - val_loss: 2.0251 - val_accuracy: 0.2473\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 2.1335 - accuracy: 0.1967 - val_loss: 2.1188 - val_accuracy: 0.2207\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 2.1793 - accuracy: 0.1691 - val_loss: 2.1397 - val_accuracy: 0.1620\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.2076 - accuracy: 0.1597 - val_loss: 2.1499 - val_accuracy: 0.2103\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 2.1868 - accuracy: 0.1759 - val_loss: 2.1393 - val_accuracy: 0.1958\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 2.1624 - accuracy: 0.1778 - val_loss: 2.1943 - val_accuracy: 0.1649\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 2.2740 - accuracy: 0.1681 - val_loss: 2.2176 - val_accuracy: 0.1727\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 2.2251 - accuracy: 0.1586 - val_loss: 2.1327 - val_accuracy: 0.1904\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 2.1851 - accuracy: 0.1635 - val_loss: 2.1686 - val_accuracy: 0.1747\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 2.1839 - accuracy: 0.1644 - val_loss: 2.1617 - val_accuracy: 0.1690\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 2.1742 - accuracy: 0.1762 - val_loss: 2.1280 - val_accuracy: 0.1920\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 2.1909 - accuracy: 0.1619 - val_loss: 2.1361 - val_accuracy: 0.1752\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 2.2385 - accuracy: 0.1490 - val_loss: 2.3169 - val_accuracy: 0.1129\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.2464 - accuracy: 0.1541 - val_loss: 2.1796 - val_accuracy: 0.1892\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.2797 - accuracy: 0.1498 - val_loss: 2.1758 - val_accuracy: 0.1752\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.2292 - accuracy: 0.1557 - val_loss: 2.2861 - val_accuracy: 0.1342\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 2.2219 - accuracy: 0.1506 - val_loss: 2.2761 - val_accuracy: 0.1245\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 2.2300 - accuracy: 0.1453 - val_loss: 2.1872 - val_accuracy: 0.1729\n",
      "Experiment with Regulizer = 0.010000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 10.1793 - accuracy: 0.2845 - val_loss: 6.0685 - val_accuracy: 0.2719\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 4.3459 - accuracy: 0.3042 - val_loss: 3.3884 - val_accuracy: 0.2466\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 2.6860 - accuracy: 0.3010 - val_loss: 2.3267 - val_accuracy: 0.3061\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 2.1771 - accuracy: 0.3069 - val_loss: 2.2026 - val_accuracy: 0.2742\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 2.0538 - accuracy: 0.2917 - val_loss: 1.9772 - val_accuracy: 0.3260\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.9986 - accuracy: 0.2971 - val_loss: 1.9177 - val_accuracy: 0.3318\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9793 - accuracy: 0.3013 - val_loss: 1.8960 - val_accuracy: 0.3323\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.9663 - accuracy: 0.3024 - val_loss: 2.0221 - val_accuracy: 0.2615\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.9592 - accuracy: 0.3073 - val_loss: 1.9020 - val_accuracy: 0.3403\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.9531 - accuracy: 0.3116 - val_loss: 1.8786 - val_accuracy: 0.3417\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.9453 - accuracy: 0.3172 - val_loss: 1.9639 - val_accuracy: 0.3157\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9505 - accuracy: 0.3144 - val_loss: 1.9371 - val_accuracy: 0.3238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9628 - accuracy: 0.3052 - val_loss: 2.0484 - val_accuracy: 0.2723\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9583 - accuracy: 0.3057 - val_loss: 1.9684 - val_accuracy: 0.2796\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9765 - accuracy: 0.2984 - val_loss: 1.9291 - val_accuracy: 0.3310\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 1.9511 - accuracy: 0.3109 - val_loss: 1.8933 - val_accuracy: 0.3343\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 2.0031 - accuracy: 0.2920 - val_loss: 1.9579 - val_accuracy: 0.3193\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9817 - accuracy: 0.2986 - val_loss: 1.9728 - val_accuracy: 0.2776\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9704 - accuracy: 0.2973 - val_loss: 1.9522 - val_accuracy: 0.3215\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.9613 - accuracy: 0.3040 - val_loss: 2.1090 - val_accuracy: 0.2709\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9535 - accuracy: 0.3113 - val_loss: 2.0235 - val_accuracy: 0.2685\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9533 - accuracy: 0.3109 - val_loss: 1.9593 - val_accuracy: 0.3130\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9865 - accuracy: 0.2968 - val_loss: 2.0214 - val_accuracy: 0.2756\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.9752 - accuracy: 0.2949 - val_loss: 1.9076 - val_accuracy: 0.3360\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.9634 - accuracy: 0.3049 - val_loss: 2.0608 - val_accuracy: 0.2775\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9608 - accuracy: 0.3039 - val_loss: 2.0346 - val_accuracy: 0.2656\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9685 - accuracy: 0.3035 - val_loss: 2.0012 - val_accuracy: 0.2857\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.9758 - accuracy: 0.2972 - val_loss: 2.0253 - val_accuracy: 0.2598\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.9681 - accuracy: 0.2984 - val_loss: 1.9988 - val_accuracy: 0.2734\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9722 - accuracy: 0.3021 - val_loss: 1.9287 - val_accuracy: 0.3293\n",
      "Experiment with Regulizer = 0.010000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 14.2872 - accuracy: 0.2653 - val_loss: 12.1937 - val_accuracy: 0.3288\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 10.7402 - accuracy: 0.3392 - val_loss: 9.4656 - val_accuracy: 0.3292\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 8.2814 - accuracy: 0.3648 - val_loss: 7.2437 - val_accuracy: 0.3972\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 6.5144 - accuracy: 0.3755 - val_loss: 5.7731 - val_accuracy: 0.3985\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 5.2388 - accuracy: 0.3825 - val_loss: 4.6874 - val_accuracy: 0.3952\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 4.2992 - accuracy: 0.3861 - val_loss: 3.8502 - val_accuracy: 0.4133\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 3.6095 - accuracy: 0.3909 - val_loss: 3.3176 - val_accuracy: 0.3959\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 3.1037 - accuracy: 0.3912 - val_loss: 2.8920 - val_accuracy: 0.3965\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 2.7508 - accuracy: 0.3934 - val_loss: 2.6214 - val_accuracy: 0.3735\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 2.4859 - accuracy: 0.3954 - val_loss: 2.3977 - val_accuracy: 0.3923\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 2.2735 - accuracy: 0.4032 - val_loss: 2.2552 - val_accuracy: 0.3692\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 2.1368 - accuracy: 0.4012 - val_loss: 2.0113 - val_accuracy: 0.4246\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 2.0120 - accuracy: 0.4110 - val_loss: 1.8907 - val_accuracy: 0.4344\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.9339 - accuracy: 0.4103 - val_loss: 1.8933 - val_accuracy: 0.3984\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.8873 - accuracy: 0.4083 - val_loss: 1.8268 - val_accuracy: 0.4191\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.8823 - accuracy: 0.3958 - val_loss: 1.8523 - val_accuracy: 0.4060\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8367 - accuracy: 0.4045 - val_loss: 1.7873 - val_accuracy: 0.4270\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.8145 - accuracy: 0.4048 - val_loss: 1.7922 - val_accuracy: 0.4041\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7804 - accuracy: 0.4113 - val_loss: 1.8140 - val_accuracy: 0.3984\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7703 - accuracy: 0.4120 - val_loss: 1.7615 - val_accuracy: 0.4030\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.7446 - accuracy: 0.4167 - val_loss: 1.7834 - val_accuracy: 0.4093\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7342 - accuracy: 0.4212 - val_loss: 1.7065 - val_accuracy: 0.4374\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7350 - accuracy: 0.4207 - val_loss: 1.7195 - val_accuracy: 0.4273\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7261 - accuracy: 0.4190 - val_loss: 1.7162 - val_accuracy: 0.4203\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7209 - accuracy: 0.4223 - val_loss: 1.8182 - val_accuracy: 0.3840\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.7259 - accuracy: 0.4185 - val_loss: 1.7127 - val_accuracy: 0.4245\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7088 - accuracy: 0.4251 - val_loss: 1.6956 - val_accuracy: 0.4311\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7096 - accuracy: 0.4239 - val_loss: 1.6747 - val_accuracy: 0.4366\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7109 - accuracy: 0.4216 - val_loss: 1.7221 - val_accuracy: 0.4262\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7038 - accuracy: 0.4258 - val_loss: 1.8967 - val_accuracy: 0.3627\n",
      "Experiment with Regulizer = 0.010000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 15.3079 - accuracy: 0.2486 - val_loss: 13.9225 - val_accuracy: 0.3218\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 13.0692 - accuracy: 0.3280 - val_loss: 12.0876 - val_accuracy: 0.3580\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 11.3197 - accuracy: 0.3645 - val_loss: 10.4778 - val_accuracy: 0.4027\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 9.8729 - accuracy: 0.3858 - val_loss: 9.1609 - val_accuracy: 0.4205\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 8.6446 - accuracy: 0.4002 - val_loss: 8.0652 - val_accuracy: 0.4128\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 7.6055 - accuracy: 0.4138 - val_loss: 7.0817 - val_accuracy: 0.4384\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 6.7188 - accuracy: 0.4223 - val_loss: 6.3027 - val_accuracy: 0.4372\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 5.9747 - accuracy: 0.4249 - val_loss: 5.6223 - val_accuracy: 0.4207\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 5.3353 - accuracy: 0.4300 - val_loss: 5.0576 - val_accuracy: 0.4324\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 4.8126 - accuracy: 0.4292 - val_loss: 4.5667 - val_accuracy: 0.4208\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 4.3434 - accuracy: 0.4303 - val_loss: 4.1259 - val_accuracy: 0.4310\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 3.9417 - accuracy: 0.4355 - val_loss: 3.7713 - val_accuracy: 0.4324\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 3.5975 - accuracy: 0.4404 - val_loss: 3.4750 - val_accuracy: 0.4187\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 3.3137 - accuracy: 0.4398 - val_loss: 3.2719 - val_accuracy: 0.4210\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 3.0593 - accuracy: 0.4428 - val_loss: 3.0077 - val_accuracy: 0.4142\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.8563 - accuracy: 0.4407 - val_loss: 2.8255 - val_accuracy: 0.4184\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.6645 - accuracy: 0.4464 - val_loss: 2.5899 - val_accuracy: 0.4398\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.5124 - accuracy: 0.4507 - val_loss: 2.3860 - val_accuracy: 0.4628\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.3820 - accuracy: 0.4498 - val_loss: 2.3125 - val_accuracy: 0.4444\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.2601 - accuracy: 0.4565 - val_loss: 2.1960 - val_accuracy: 0.4640\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.1548 - accuracy: 0.4569 - val_loss: 2.1556 - val_accuracy: 0.4368\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.0855 - accuracy: 0.4571 - val_loss: 2.0497 - val_accuracy: 0.4528\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.0149 - accuracy: 0.4557 - val_loss: 2.0373 - val_accuracy: 0.4255\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.9639 - accuracy: 0.4502 - val_loss: 2.0227 - val_accuracy: 0.4140\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.9158 - accuracy: 0.4526 - val_loss: 1.9530 - val_accuracy: 0.4376\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.8749 - accuracy: 0.4514 - val_loss: 1.8661 - val_accuracy: 0.4370\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.8342 - accuracy: 0.4579 - val_loss: 1.7686 - val_accuracy: 0.4725\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7957 - accuracy: 0.4555 - val_loss: 1.8104 - val_accuracy: 0.4435\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7656 - accuracy: 0.4589 - val_loss: 1.7668 - val_accuracy: 0.4494\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7367 - accuracy: 0.4636 - val_loss: 1.7572 - val_accuracy: 0.4496\n",
      "Experiment with Regulizer = 0.000100\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 3.9946 - accuracy: 0.1405 - val_loss: 4.0164 - val_accuracy: 0.1876\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 4.1039 - accuracy: 0.1571 - val_loss: 4.0764 - val_accuracy: 0.2032\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 4.0553 - accuracy: 0.1548 - val_loss: 4.0305 - val_accuracy: 0.1995\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 6.1825 - accuracy: 0.1569 - val_loss: 8.3739 - val_accuracy: 0.2087\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 7.9571 - accuracy: 0.1580 - val_loss: 7.7096 - val_accuracy: 0.1856\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 7.1806 - accuracy: 0.1553 - val_loss: 7.1206 - val_accuracy: 0.1976\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 6.5746 - accuracy: 0.1537 - val_loss: 6.7983 - val_accuracy: 0.1821\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 6.1418 - accuracy: 0.1496 - val_loss: 6.0281 - val_accuracy: 0.2076\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 5.6132 - accuracy: 0.1505 - val_loss: 5.6766 - val_accuracy: 0.2008\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 5.2298 - accuracy: 0.1506 - val_loss: 5.3986 - val_accuracy: 0.1800\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 5.0276 - accuracy: 0.1491 - val_loss: 5.3777 - val_accuracy: 0.1814\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 5.1142 - accuracy: 0.1515 - val_loss: 5.6340 - val_accuracy: 0.1983\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 5.1108 - accuracy: 0.1562 - val_loss: 5.5991 - val_accuracy: 0.1885\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 5.0587 - accuracy: 0.1527 - val_loss: 5.8632 - val_accuracy: 0.2010\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 4.9626 - accuracy: 0.1524 - val_loss: 5.1306 - val_accuracy: 0.1754\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 4.8703 - accuracy: 0.1514 - val_loss: 5.8520 - val_accuracy: 0.1984\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 6.1747 - accuracy: 0.1548 - val_loss: 6.5406 - val_accuracy: 0.1802\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 5.8087 - accuracy: 0.1523 - val_loss: 5.9846 - val_accuracy: 0.1933\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 5.3121 - accuracy: 0.1529 - val_loss: 5.4562 - val_accuracy: 0.2010\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 5.0999 - accuracy: 0.1472 - val_loss: 5.4588 - val_accuracy: 0.1721\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 4.9208 - accuracy: 0.1429 - val_loss: 5.2014 - val_accuracy: 0.1873\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 4.6839 - accuracy: 0.1434 - val_loss: 4.7556 - val_accuracy: 0.2030\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 4.4287 - accuracy: 0.1466 - val_loss: 4.7872 - val_accuracy: 0.1717\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 4.4232 - accuracy: 0.1438 - val_loss: 7.3514 - val_accuracy: 0.1878\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 6.8733 - accuracy: 0.1412 - val_loss: 6.7910 - val_accuracy: 0.2212\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 6.1950 - accuracy: 0.1415 - val_loss: 6.1621 - val_accuracy: 0.2030\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 6.7813 - accuracy: 0.1468 - val_loss: 12.7960 - val_accuracy: 0.2076\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 11.5995 - accuracy: 0.1466 - val_loss: 11.1503 - val_accuracy: 0.2066\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 10.3954 - accuracy: 0.1468 - val_loss: 10.0392 - val_accuracy: 0.2043\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 9.0481 - accuracy: 0.1473 - val_loss: 8.5987 - val_accuracy: 0.1807\n",
      "Experiment with Regulizer = 0.000100\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 2.1768 - accuracy: 0.2678 - val_loss: 1.9552 - val_accuracy: 0.3515\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.0781 - accuracy: 0.2933 - val_loss: 2.0811 - val_accuracy: 0.2705\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.1006 - accuracy: 0.2838 - val_loss: 2.0066 - val_accuracy: 0.3304\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 2.1147 - accuracy: 0.2717 - val_loss: 1.9971 - val_accuracy: 0.3285\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.0830 - accuracy: 0.2909 - val_loss: 1.9946 - val_accuracy: 0.3294\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 2.0783 - accuracy: 0.2899 - val_loss: 1.9834 - val_accuracy: 0.3360\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 2.0862 - accuracy: 0.2852 - val_loss: 1.9861 - val_accuracy: 0.3335\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 2.0676 - accuracy: 0.2931 - val_loss: 1.9653 - val_accuracy: 0.3464\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 2.0659 - accuracy: 0.2925 - val_loss: 1.9452 - val_accuracy: 0.3518\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 2.0490 - accuracy: 0.2948 - val_loss: 2.0040 - val_accuracy: 0.3163\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 2.0474 - accuracy: 0.2935 - val_loss: 1.9623 - val_accuracy: 0.3355\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 2.0611 - accuracy: 0.2918 - val_loss: 1.9835 - val_accuracy: 0.3461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 2.0371 - accuracy: 0.2982 - val_loss: 1.9407 - val_accuracy: 0.3597\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.0190 - accuracy: 0.3112 - val_loss: 1.9195 - val_accuracy: 0.3590\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.0098 - accuracy: 0.3127 - val_loss: 1.9234 - val_accuracy: 0.3549\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.0231 - accuracy: 0.3073 - val_loss: 1.9271 - val_accuracy: 0.3678\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 2.0323 - accuracy: 0.3019 - val_loss: 1.9466 - val_accuracy: 0.3491\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 2.0089 - accuracy: 0.3090 - val_loss: 1.9579 - val_accuracy: 0.3534\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 2.0091 - accuracy: 0.3071 - val_loss: 1.9054 - val_accuracy: 0.3572\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9958 - accuracy: 0.3163 - val_loss: 1.9330 - val_accuracy: 0.3522\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9830 - accuracy: 0.3182 - val_loss: 1.8961 - val_accuracy: 0.3531\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 1.9797 - accuracy: 0.3193 - val_loss: 1.8786 - val_accuracy: 0.3607\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9731 - accuracy: 0.3192 - val_loss: 1.8812 - val_accuracy: 0.3703\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9690 - accuracy: 0.3247 - val_loss: 1.8914 - val_accuracy: 0.3669\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 21s 428us/step - loss: 1.9625 - accuracy: 0.3235 - val_loss: 1.8989 - val_accuracy: 0.3571\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 1.9424 - accuracy: 0.3326 - val_loss: 1.9248 - val_accuracy: 0.3496\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9402 - accuracy: 0.3320 - val_loss: 1.8427 - val_accuracy: 0.3828\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9556 - accuracy: 0.3277 - val_loss: 1.9444 - val_accuracy: 0.3323\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9639 - accuracy: 0.3195 - val_loss: 1.9149 - val_accuracy: 0.3542\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9478 - accuracy: 0.3275 - val_loss: 1.9240 - val_accuracy: 0.3446\n",
      "Experiment with Regulizer = 0.000100\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 12s 239us/step - loss: 2.1553 - accuracy: 0.2831 - val_loss: 1.9214 - val_accuracy: 0.3445\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9760 - accuracy: 0.3365 - val_loss: 1.9011 - val_accuracy: 0.3719\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9671 - accuracy: 0.3381 - val_loss: 1.8514 - val_accuracy: 0.3937\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.9543 - accuracy: 0.3447 - val_loss: 1.8402 - val_accuracy: 0.3872\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9574 - accuracy: 0.3412 - val_loss: 1.8972 - val_accuracy: 0.3499\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.9670 - accuracy: 0.3366 - val_loss: 1.8454 - val_accuracy: 0.3944\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.9615 - accuracy: 0.3391 - val_loss: 1.8541 - val_accuracy: 0.3894\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9558 - accuracy: 0.3409 - val_loss: 1.8652 - val_accuracy: 0.3877\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.9306 - accuracy: 0.3503 - val_loss: 1.8573 - val_accuracy: 0.3800\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.9160 - accuracy: 0.3561 - val_loss: 1.8197 - val_accuracy: 0.3999\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8966 - accuracy: 0.3612 - val_loss: 1.7728 - val_accuracy: 0.4237\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.8821 - accuracy: 0.3668 - val_loss: 1.8084 - val_accuracy: 0.4077\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.8741 - accuracy: 0.3710 - val_loss: 1.7727 - val_accuracy: 0.4230\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8542 - accuracy: 0.3783 - val_loss: 1.7901 - val_accuracy: 0.4149\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8557 - accuracy: 0.3788 - val_loss: 1.7196 - val_accuracy: 0.4406\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8381 - accuracy: 0.3824 - val_loss: 1.7615 - val_accuracy: 0.4120\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8399 - accuracy: 0.3835 - val_loss: 1.7295 - val_accuracy: 0.4297\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8328 - accuracy: 0.3831 - val_loss: 1.7603 - val_accuracy: 0.4172\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8292 - accuracy: 0.3850 - val_loss: 1.7407 - val_accuracy: 0.4325\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8118 - accuracy: 0.3911 - val_loss: 1.7391 - val_accuracy: 0.4246\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.8108 - accuracy: 0.3933 - val_loss: 1.7487 - val_accuracy: 0.4258\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7959 - accuracy: 0.3980 - val_loss: 1.7224 - val_accuracy: 0.4304\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7973 - accuracy: 0.3983 - val_loss: 1.7250 - val_accuracy: 0.4287\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7870 - accuracy: 0.3998 - val_loss: 1.6645 - val_accuracy: 0.4544\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.7833 - accuracy: 0.4021 - val_loss: 1.6837 - val_accuracy: 0.4376\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 1.7740 - accuracy: 0.4051 - val_loss: 1.7009 - val_accuracy: 0.4317\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7674 - accuracy: 0.4056 - val_loss: 1.6819 - val_accuracy: 0.4445\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7615 - accuracy: 0.4083 - val_loss: 1.6916 - val_accuracy: 0.4447\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.7474 - accuracy: 0.4133 - val_loss: 1.6753 - val_accuracy: 0.4486\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7428 - accuracy: 0.4133 - val_loss: 1.6488 - val_accuracy: 0.4492\n",
      "Experiment with Regulizer = 0.000100\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.2975 - accuracy: 0.2652 - val_loss: 1.9163 - val_accuracy: 0.3573\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.9706 - accuracy: 0.3451 - val_loss: 1.7915 - val_accuracy: 0.4102\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.8748 - accuracy: 0.3770 - val_loss: 1.7379 - val_accuracy: 0.4252\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.8223 - accuracy: 0.3961 - val_loss: 1.7182 - val_accuracy: 0.4393\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7899 - accuracy: 0.4080 - val_loss: 1.6888 - val_accuracy: 0.4470\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7675 - accuracy: 0.4162 - val_loss: 1.7307 - val_accuracy: 0.4355\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7501 - accuracy: 0.4212 - val_loss: 1.6726 - val_accuracy: 0.4540\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7358 - accuracy: 0.4273 - val_loss: 1.6733 - val_accuracy: 0.4463\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7278 - accuracy: 0.4275 - val_loss: 1.6647 - val_accuracy: 0.4530\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7123 - accuracy: 0.4352 - val_loss: 1.6567 - val_accuracy: 0.4511\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7083 - accuracy: 0.4350 - val_loss: 1.6248 - val_accuracy: 0.4757\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6945 - accuracy: 0.4430 - val_loss: 1.6278 - val_accuracy: 0.4637\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6819 - accuracy: 0.4493 - val_loss: 1.6286 - val_accuracy: 0.4690\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6757 - accuracy: 0.4493 - val_loss: 1.6589 - val_accuracy: 0.4548\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6653 - accuracy: 0.4483 - val_loss: 1.6181 - val_accuracy: 0.4679\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6541 - accuracy: 0.4539 - val_loss: 1.6180 - val_accuracy: 0.4786\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6522 - accuracy: 0.4554 - val_loss: 1.6300 - val_accuracy: 0.4650\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6517 - accuracy: 0.4577 - val_loss: 1.6015 - val_accuracy: 0.4747\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6453 - accuracy: 0.4585 - val_loss: 1.5959 - val_accuracy: 0.4779\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6454 - accuracy: 0.4593 - val_loss: 1.6280 - val_accuracy: 0.4687\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6336 - accuracy: 0.4622 - val_loss: 1.5985 - val_accuracy: 0.4739\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6211 - accuracy: 0.4667 - val_loss: 1.6016 - val_accuracy: 0.4709\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6216 - accuracy: 0.4679 - val_loss: 1.6428 - val_accuracy: 0.4580\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6145 - accuracy: 0.4699 - val_loss: 1.5890 - val_accuracy: 0.4814\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6064 - accuracy: 0.4717 - val_loss: 1.5878 - val_accuracy: 0.4788\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6028 - accuracy: 0.4727 - val_loss: 1.5616 - val_accuracy: 0.4909\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5968 - accuracy: 0.4755 - val_loss: 1.5629 - val_accuracy: 0.4921\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6052 - accuracy: 0.4719 - val_loss: 1.5976 - val_accuracy: 0.4800\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5878 - accuracy: 0.4779 - val_loss: 1.5645 - val_accuracy: 0.4838\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5727 - accuracy: 0.4824 - val_loss: 1.5574 - val_accuracy: 0.4885\n",
      "Experiment with Regulizer = 0.000100\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 2.4134 - accuracy: 0.2477 - val_loss: 1.9703 - val_accuracy: 0.3445\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.0593 - accuracy: 0.3244 - val_loss: 1.8679 - val_accuracy: 0.3880\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.9317 - accuracy: 0.3633 - val_loss: 1.7751 - val_accuracy: 0.4103\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.8678 - accuracy: 0.3858 - val_loss: 1.7037 - val_accuracy: 0.4443\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.8175 - accuracy: 0.3996 - val_loss: 1.7035 - val_accuracy: 0.4347\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7701 - accuracy: 0.4167 - val_loss: 1.6732 - val_accuracy: 0.4515\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7467 - accuracy: 0.4239 - val_loss: 1.6671 - val_accuracy: 0.4462\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7209 - accuracy: 0.4315 - val_loss: 1.6439 - val_accuracy: 0.4609\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7010 - accuracy: 0.4406 - val_loss: 1.6566 - val_accuracy: 0.4527\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6806 - accuracy: 0.4469 - val_loss: 1.6222 - val_accuracy: 0.4707\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6608 - accuracy: 0.4534 - val_loss: 1.5992 - val_accuracy: 0.4725\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6499 - accuracy: 0.4597 - val_loss: 1.5861 - val_accuracy: 0.4775\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6374 - accuracy: 0.4598 - val_loss: 1.5874 - val_accuracy: 0.4793\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6264 - accuracy: 0.4659 - val_loss: 1.5672 - val_accuracy: 0.4928\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6081 - accuracy: 0.4722 - val_loss: 1.5792 - val_accuracy: 0.4808\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5991 - accuracy: 0.4726 - val_loss: 1.5654 - val_accuracy: 0.4878\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5871 - accuracy: 0.4805 - val_loss: 1.5769 - val_accuracy: 0.4814\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5709 - accuracy: 0.4832 - val_loss: 1.5901 - val_accuracy: 0.4827\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5670 - accuracy: 0.4824 - val_loss: 1.5584 - val_accuracy: 0.4895\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5545 - accuracy: 0.4870 - val_loss: 1.5621 - val_accuracy: 0.4855\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5431 - accuracy: 0.4957 - val_loss: 1.5404 - val_accuracy: 0.4955\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5381 - accuracy: 0.4973 - val_loss: 1.5395 - val_accuracy: 0.4973\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5307 - accuracy: 0.5000 - val_loss: 1.5434 - val_accuracy: 0.4944\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5218 - accuracy: 0.5002 - val_loss: 1.5310 - val_accuracy: 0.4962\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5137 - accuracy: 0.5067 - val_loss: 1.5679 - val_accuracy: 0.4840\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5090 - accuracy: 0.5075 - val_loss: 1.5125 - val_accuracy: 0.5013\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5081 - accuracy: 0.5047 - val_loss: 1.5459 - val_accuracy: 0.4935\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5020 - accuracy: 0.5075 - val_loss: 1.5347 - val_accuracy: 0.4978\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5023 - accuracy: 0.5074 - val_loss: 1.5485 - val_accuracy: 0.4899\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4902 - accuracy: 0.5127 - val_loss: 1.5211 - val_accuracy: 0.5026\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.3120 - accuracy: 0.1443 - val_loss: 2.2674 - val_accuracy: 0.2098\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2473 - accuracy: 0.1599 - val_loss: 2.3473 - val_accuracy: 0.2106\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2536 - accuracy: 0.1534 - val_loss: 2.4649 - val_accuracy: 0.2181\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2525 - accuracy: 0.1550 - val_loss: 2.4382 - val_accuracy: 0.1822\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2544 - accuracy: 0.1538 - val_loss: 2.4404 - val_accuracy: 0.2082\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2566 - accuracy: 0.1498 - val_loss: 2.3952 - val_accuracy: 0.1965\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2560 - accuracy: 0.1527 - val_loss: 2.3419 - val_accuracy: 0.2288\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2531 - accuracy: 0.1539 - val_loss: 2.4206 - val_accuracy: 0.2005\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2546 - accuracy: 0.1549 - val_loss: 2.3779 - val_accuracy: 0.2269\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2562 - accuracy: 0.1540 - val_loss: 2.4198 - val_accuracy: 0.1977\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2619 - accuracy: 0.1493 - val_loss: 2.3671 - val_accuracy: 0.2201\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 2.2599 - accuracy: 0.1517 - val_loss: 2.3995 - val_accuracy: 0.2084\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 2.2550 - accuracy: 0.1544 - val_loss: 2.2797 - val_accuracy: 0.2146\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2576 - accuracy: 0.1503 - val_loss: 2.3207 - val_accuracy: 0.1661\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2545 - accuracy: 0.1487 - val_loss: 2.3895 - val_accuracy: 0.2227\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2526 - accuracy: 0.1510 - val_loss: 2.3835 - val_accuracy: 0.2062\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2572 - accuracy: 0.1503 - val_loss: 2.3722 - val_accuracy: 0.1853\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2555 - accuracy: 0.1503 - val_loss: 2.4883 - val_accuracy: 0.2044\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2563 - accuracy: 0.1511 - val_loss: 2.3291 - val_accuracy: 0.1818\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2562 - accuracy: 0.1461 - val_loss: 2.3647 - val_accuracy: 0.2116\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2617 - accuracy: 0.1472 - val_loss: 2.3410 - val_accuracy: 0.2129\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2832 - accuracy: 0.1472 - val_loss: 2.3164 - val_accuracy: 0.1733\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2866 - accuracy: 0.1480 - val_loss: 2.3406 - val_accuracy: 0.1743\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2875 - accuracy: 0.1462 - val_loss: 2.3405 - val_accuracy: 0.1668\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2899 - accuracy: 0.1464 - val_loss: 2.3832 - val_accuracy: 0.1883\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2898 - accuracy: 0.1462 - val_loss: 2.3565 - val_accuracy: 0.1931\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2895 - accuracy: 0.1465 - val_loss: 2.4305 - val_accuracy: 0.2100\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2877 - accuracy: 0.1472 - val_loss: 2.3255 - val_accuracy: 0.1922\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2873 - accuracy: 0.1489 - val_loss: 2.2992 - val_accuracy: 0.1820\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2909 - accuracy: 0.1456 - val_loss: 2.3581 - val_accuracy: 0.1816\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 2.0437 - accuracy: 0.2658 - val_loss: 1.8321 - val_accuracy: 0.3315\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9271 - accuracy: 0.2988 - val_loss: 1.8174 - val_accuracy: 0.3313\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 21s 428us/step - loss: 1.9301 - accuracy: 0.2966 - val_loss: 1.8470 - val_accuracy: 0.3408\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 1.9411 - accuracy: 0.2940 - val_loss: 1.7893 - val_accuracy: 0.3603\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 1.9249 - accuracy: 0.3011 - val_loss: 1.8655 - val_accuracy: 0.3238\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.9596 - accuracy: 0.2810 - val_loss: 1.8861 - val_accuracy: 0.3076\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.9597 - accuracy: 0.2816 - val_loss: 1.8927 - val_accuracy: 0.3376\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9426 - accuracy: 0.2913 - val_loss: 1.9357 - val_accuracy: 0.3091\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 1.9462 - accuracy: 0.2929 - val_loss: 1.8534 - val_accuracy: 0.3464\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 1.9296 - accuracy: 0.2987 - val_loss: 1.8468 - val_accuracy: 0.3463\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9226 - accuracy: 0.3006 - val_loss: 1.8234 - val_accuracy: 0.3486\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 21s 428us/step - loss: 1.9036 - accuracy: 0.3100 - val_loss: 1.8833 - val_accuracy: 0.3256\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9343 - accuracy: 0.2948 - val_loss: 1.8706 - val_accuracy: 0.3267\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9230 - accuracy: 0.2968 - val_loss: 1.8584 - val_accuracy: 0.3387\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9130 - accuracy: 0.3032 - val_loss: 1.9100 - val_accuracy: 0.3166\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9345 - accuracy: 0.2933 - val_loss: 1.8473 - val_accuracy: 0.3391\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.9241 - accuracy: 0.2989 - val_loss: 1.8417 - val_accuracy: 0.3416\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9118 - accuracy: 0.2987 - val_loss: 1.8415 - val_accuracy: 0.3474\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 21s 428us/step - loss: 1.9037 - accuracy: 0.3057 - val_loss: 1.8390 - val_accuracy: 0.3357\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.8934 - accuracy: 0.3116 - val_loss: 1.8268 - val_accuracy: 0.3522\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9110 - accuracy: 0.3014 - val_loss: 1.9282 - val_accuracy: 0.3050\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9177 - accuracy: 0.2962 - val_loss: 1.8570 - val_accuracy: 0.3209\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 21s 428us/step - loss: 1.9106 - accuracy: 0.3052 - val_loss: 1.8358 - val_accuracy: 0.3552\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.9113 - accuracy: 0.3030 - val_loss: 1.8404 - val_accuracy: 0.3441\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 21s 428us/step - loss: 1.9112 - accuracy: 0.3039 - val_loss: 1.8175 - val_accuracy: 0.3597\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.8941 - accuracy: 0.3122 - val_loss: 1.7880 - val_accuracy: 0.3670\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 1.8885 - accuracy: 0.3150 - val_loss: 1.7751 - val_accuracy: 0.3799\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 21s 428us/step - loss: 1.8857 - accuracy: 0.3175 - val_loss: 1.8334 - val_accuracy: 0.3343\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 1.8873 - accuracy: 0.3134 - val_loss: 1.8791 - val_accuracy: 0.3177\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 1.8775 - accuracy: 0.3190 - val_loss: 1.7710 - val_accuracy: 0.3884\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 12s 238us/step - loss: 2.0139 - accuracy: 0.2856 - val_loss: 1.7425 - val_accuracy: 0.3667\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8432 - accuracy: 0.3327 - val_loss: 1.7601 - val_accuracy: 0.3655\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.8301 - accuracy: 0.3384 - val_loss: 1.7586 - val_accuracy: 0.3683\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8123 - accuracy: 0.3459 - val_loss: 1.7022 - val_accuracy: 0.3915\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.8038 - accuracy: 0.3466 - val_loss: 1.7169 - val_accuracy: 0.3867\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8081 - accuracy: 0.3502 - val_loss: 1.7028 - val_accuracy: 0.3865\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.8007 - accuracy: 0.3512 - val_loss: 1.7207 - val_accuracy: 0.3892\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8011 - accuracy: 0.3527 - val_loss: 1.7450 - val_accuracy: 0.3893\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.7820 - accuracy: 0.3582 - val_loss: 1.6866 - val_accuracy: 0.4122\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7688 - accuracy: 0.3654 - val_loss: 1.6548 - val_accuracy: 0.4162\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7614 - accuracy: 0.3645 - val_loss: 1.6818 - val_accuracy: 0.3928\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.7681 - accuracy: 0.3635 - val_loss: 1.6630 - val_accuracy: 0.4105\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.7605 - accuracy: 0.3643 - val_loss: 1.6618 - val_accuracy: 0.4023\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7248 - accuracy: 0.3778 - val_loss: 1.6356 - val_accuracy: 0.4211\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.7270 - accuracy: 0.3833 - val_loss: 1.5915 - val_accuracy: 0.4421\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7073 - accuracy: 0.3851 - val_loss: 1.5933 - val_accuracy: 0.4344\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7044 - accuracy: 0.3862 - val_loss: 1.6292 - val_accuracy: 0.4110\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.7237 - accuracy: 0.3775 - val_loss: 1.6513 - val_accuracy: 0.4243\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7077 - accuracy: 0.3872 - val_loss: 1.6006 - val_accuracy: 0.4450\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.6933 - accuracy: 0.3909 - val_loss: 1.6568 - val_accuracy: 0.4154\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.6896 - accuracy: 0.3939 - val_loss: 1.5957 - val_accuracy: 0.4392\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.6793 - accuracy: 0.3969 - val_loss: 1.5740 - val_accuracy: 0.4426\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.6787 - accuracy: 0.3999 - val_loss: 1.6200 - val_accuracy: 0.4370\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.6706 - accuracy: 0.4041 - val_loss: 1.5537 - val_accuracy: 0.4639\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.6649 - accuracy: 0.4033 - val_loss: 1.6044 - val_accuracy: 0.4395\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.6603 - accuracy: 0.4053 - val_loss: 1.5548 - val_accuracy: 0.4505\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.6573 - accuracy: 0.4068 - val_loss: 1.5741 - val_accuracy: 0.4399\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.6497 - accuracy: 0.4088 - val_loss: 1.5736 - val_accuracy: 0.4438\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.6397 - accuracy: 0.4130 - val_loss: 1.5688 - val_accuracy: 0.4492\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.6400 - accuracy: 0.4136 - val_loss: 1.5773 - val_accuracy: 0.4388\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.1469 - accuracy: 0.2665 - val_loss: 1.7586 - val_accuracy: 0.3601\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.8304 - accuracy: 0.3478 - val_loss: 1.6839 - val_accuracy: 0.3909\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7429 - accuracy: 0.3733 - val_loss: 1.5951 - val_accuracy: 0.4241\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6881 - accuracy: 0.3919 - val_loss: 1.6075 - val_accuracy: 0.4183\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6528 - accuracy: 0.4065 - val_loss: 1.5464 - val_accuracy: 0.4438\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6401 - accuracy: 0.4113 - val_loss: 1.5443 - val_accuracy: 0.4394\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.6159 - accuracy: 0.4234 - val_loss: 1.5325 - val_accuracy: 0.4504\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6007 - accuracy: 0.4286 - val_loss: 1.5365 - val_accuracy: 0.4467\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5955 - accuracy: 0.4275 - val_loss: 1.5408 - val_accuracy: 0.4495\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5844 - accuracy: 0.4326 - val_loss: 1.5020 - val_accuracy: 0.4638\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5695 - accuracy: 0.4359 - val_loss: 1.5120 - val_accuracy: 0.4588\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5586 - accuracy: 0.4414 - val_loss: 1.4795 - val_accuracy: 0.4715\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5484 - accuracy: 0.4448 - val_loss: 1.5214 - val_accuracy: 0.4424\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5447 - accuracy: 0.4469 - val_loss: 1.5413 - val_accuracy: 0.4484\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5353 - accuracy: 0.4504 - val_loss: 1.4766 - val_accuracy: 0.4716\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5255 - accuracy: 0.4517 - val_loss: 1.4858 - val_accuracy: 0.4717\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5170 - accuracy: 0.4543 - val_loss: 1.5017 - val_accuracy: 0.4618\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5044 - accuracy: 0.4608 - val_loss: 1.4880 - val_accuracy: 0.4579\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5029 - accuracy: 0.4599 - val_loss: 1.4291 - val_accuracy: 0.4858\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4973 - accuracy: 0.4613 - val_loss: 1.4720 - val_accuracy: 0.4659\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4971 - accuracy: 0.4640 - val_loss: 1.4671 - val_accuracy: 0.4702\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4965 - accuracy: 0.4635 - val_loss: 1.4480 - val_accuracy: 0.4774\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4851 - accuracy: 0.4695 - val_loss: 1.4511 - val_accuracy: 0.4789\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4800 - accuracy: 0.4706 - val_loss: 1.4720 - val_accuracy: 0.4717\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4865 - accuracy: 0.4673 - val_loss: 1.4374 - val_accuracy: 0.4762\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4711 - accuracy: 0.4721 - val_loss: 1.4529 - val_accuracy: 0.4807\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4810 - accuracy: 0.4713 - val_loss: 1.4482 - val_accuracy: 0.4818\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4726 - accuracy: 0.4733 - val_loss: 1.4837 - val_accuracy: 0.4638\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4686 - accuracy: 0.4741 - val_loss: 1.4454 - val_accuracy: 0.4828\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4524 - accuracy: 0.4781 - val_loss: 1.4264 - val_accuracy: 0.4846\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 2.2429 - accuracy: 0.2475 - val_loss: 1.8478 - val_accuracy: 0.3325\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.8936 - accuracy: 0.3317 - val_loss: 1.7035 - val_accuracy: 0.3892\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7842 - accuracy: 0.3650 - val_loss: 1.6443 - val_accuracy: 0.4160\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7133 - accuracy: 0.3908 - val_loss: 1.5919 - val_accuracy: 0.4355\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6683 - accuracy: 0.4029 - val_loss: 1.5686 - val_accuracy: 0.4423\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6383 - accuracy: 0.4154 - val_loss: 1.5225 - val_accuracy: 0.4624\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6043 - accuracy: 0.4252 - val_loss: 1.5134 - val_accuracy: 0.4633\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5773 - accuracy: 0.4361 - val_loss: 1.5187 - val_accuracy: 0.4501\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5621 - accuracy: 0.4407 - val_loss: 1.4872 - val_accuracy: 0.4713\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5431 - accuracy: 0.4465 - val_loss: 1.4708 - val_accuracy: 0.4749\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5298 - accuracy: 0.4486 - val_loss: 1.4671 - val_accuracy: 0.4686\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5103 - accuracy: 0.4599 - val_loss: 1.4742 - val_accuracy: 0.4676\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4948 - accuracy: 0.4623 - val_loss: 1.4717 - val_accuracy: 0.4773\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4845 - accuracy: 0.4673 - val_loss: 1.4782 - val_accuracy: 0.4766\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4775 - accuracy: 0.4713 - val_loss: 1.4775 - val_accuracy: 0.4728\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4616 - accuracy: 0.4735 - val_loss: 1.4159 - val_accuracy: 0.4928\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4500 - accuracy: 0.4776 - val_loss: 1.4115 - val_accuracy: 0.4898\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4403 - accuracy: 0.4828 - val_loss: 1.4623 - val_accuracy: 0.4696\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4335 - accuracy: 0.4862 - val_loss: 1.4154 - val_accuracy: 0.4950\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4164 - accuracy: 0.4898 - val_loss: 1.4175 - val_accuracy: 0.4933\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4103 - accuracy: 0.4902 - val_loss: 1.3966 - val_accuracy: 0.4982\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4027 - accuracy: 0.4941 - val_loss: 1.4117 - val_accuracy: 0.4915\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3932 - accuracy: 0.4999 - val_loss: 1.4195 - val_accuracy: 0.4950\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3884 - accuracy: 0.5024 - val_loss: 1.3974 - val_accuracy: 0.4982\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3899 - accuracy: 0.5005 - val_loss: 1.4100 - val_accuracy: 0.4990\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3733 - accuracy: 0.5067 - val_loss: 1.3906 - val_accuracy: 0.5018\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3710 - accuracy: 0.5067 - val_loss: 1.3844 - val_accuracy: 0.4959\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3634 - accuracy: 0.5064 - val_loss: 1.3739 - val_accuracy: 0.5056\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3566 - accuracy: 0.5119 - val_loss: 1.3918 - val_accuracy: 0.4971\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3572 - accuracy: 0.5118 - val_loss: 1.3729 - val_accuracy: 0.5093\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.3190 - accuracy: 0.1375 - val_loss: 2.2250 - val_accuracy: 0.2109\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2465 - accuracy: 0.1598 - val_loss: 2.1879 - val_accuracy: 0.2238\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2443 - accuracy: 0.1618 - val_loss: 2.3322 - val_accuracy: 0.2028\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2487 - accuracy: 0.1556 - val_loss: 2.4967 - val_accuracy: 0.2189\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2581 - accuracy: 0.1531 - val_loss: 2.5055 - val_accuracy: 0.1973\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2530 - accuracy: 0.1561 - val_loss: 2.3881 - val_accuracy: 0.1963\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2586 - accuracy: 0.1508 - val_loss: 2.4161 - val_accuracy: 0.2036\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2577 - accuracy: 0.1512 - val_loss: 2.4146 - val_accuracy: 0.1954\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2607 - accuracy: 0.1456 - val_loss: 2.8751 - val_accuracy: 0.1683\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2603 - accuracy: 0.1467 - val_loss: 2.4834 - val_accuracy: 0.2007\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2554 - accuracy: 0.1511 - val_loss: 2.4744 - val_accuracy: 0.1848\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2535 - accuracy: 0.1523 - val_loss: 2.4977 - val_accuracy: 0.1760\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2530 - accuracy: 0.1566 - val_loss: 2.5112 - val_accuracy: 0.1993\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2526 - accuracy: 0.1518 - val_loss: 2.5944 - val_accuracy: 0.1797\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2577 - accuracy: 0.1517 - val_loss: 2.5763 - val_accuracy: 0.2109\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2505 - accuracy: 0.1527 - val_loss: 2.4629 - val_accuracy: 0.2147\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2503 - accuracy: 0.1527 - val_loss: 2.4422 - val_accuracy: 0.2083\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2538 - accuracy: 0.1531 - val_loss: 2.5758 - val_accuracy: 0.2214\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2595 - accuracy: 0.1537 - val_loss: 2.5332 - val_accuracy: 0.1915\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2596 - accuracy: 0.1522 - val_loss: 2.4828 - val_accuracy: 0.2003\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2595 - accuracy: 0.1512 - val_loss: 2.3659 - val_accuracy: 0.2028\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2552 - accuracy: 0.1532 - val_loss: 2.3058 - val_accuracy: 0.2314\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2531 - accuracy: 0.1560 - val_loss: 2.2712 - val_accuracy: 0.2224\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 164s 3ms/step - loss: 2.2527 - accuracy: 0.1544 - val_loss: 2.3861 - val_accuracy: 0.2307\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2517 - accuracy: 0.1566 - val_loss: 2.2888 - val_accuracy: 0.2051\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2503 - accuracy: 0.1570 - val_loss: 2.3330 - val_accuracy: 0.2219\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2505 - accuracy: 0.1548 - val_loss: 2.4052 - val_accuracy: 0.1963\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2494 - accuracy: 0.1570 - val_loss: 2.4585 - val_accuracy: 0.1930\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 162s 3ms/step - loss: 2.2468 - accuracy: 0.1559 - val_loss: 2.5635 - val_accuracy: 0.1950\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 163s 3ms/step - loss: 2.2490 - accuracy: 0.1560 - val_loss: 2.2906 - val_accuracy: 0.2294\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 2.0299 - accuracy: 0.2705 - val_loss: 1.8226 - val_accuracy: 0.3426\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 1.9188 - accuracy: 0.3050 - val_loss: 1.8690 - val_accuracy: 0.3340\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.9305 - accuracy: 0.2983 - val_loss: 1.8603 - val_accuracy: 0.3321\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 1.9602 - accuracy: 0.2823 - val_loss: 1.8223 - val_accuracy: 0.3337\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9838 - accuracy: 0.2737 - val_loss: 1.8655 - val_accuracy: 0.3395\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.9450 - accuracy: 0.2917 - val_loss: 1.8216 - val_accuracy: 0.3578\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9407 - accuracy: 0.2872 - val_loss: 1.8442 - val_accuracy: 0.3431\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9504 - accuracy: 0.2871 - val_loss: 1.8022 - val_accuracy: 0.3552\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9188 - accuracy: 0.3019 - val_loss: 1.8385 - val_accuracy: 0.3544\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.9153 - accuracy: 0.3063 - val_loss: 1.7989 - val_accuracy: 0.3641\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.9138 - accuracy: 0.3026 - val_loss: 1.8737 - val_accuracy: 0.3372\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.9241 - accuracy: 0.2965 - val_loss: 1.8001 - val_accuracy: 0.3598\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 1.8800 - accuracy: 0.3157 - val_loss: 1.8245 - val_accuracy: 0.3503\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 1.8823 - accuracy: 0.3149 - val_loss: 1.8667 - val_accuracy: 0.3177\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8911 - accuracy: 0.3111 - val_loss: 1.7961 - val_accuracy: 0.3575\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8667 - accuracy: 0.3177 - val_loss: 1.7912 - val_accuracy: 0.3661\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.8579 - accuracy: 0.3258 - val_loss: 1.8179 - val_accuracy: 0.3668\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.8423 - accuracy: 0.3298 - val_loss: 1.7638 - val_accuracy: 0.3895\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8564 - accuracy: 0.3245 - val_loss: 1.7744 - val_accuracy: 0.3790\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8490 - accuracy: 0.3290 - val_loss: 1.7442 - val_accuracy: 0.3860\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 1.8667 - accuracy: 0.3246 - val_loss: 1.7837 - val_accuracy: 0.3852\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8594 - accuracy: 0.3270 - val_loss: 1.7857 - val_accuracy: 0.3626\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 1.8504 - accuracy: 0.3297 - val_loss: 1.7764 - val_accuracy: 0.3788\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8459 - accuracy: 0.3318 - val_loss: 1.7595 - val_accuracy: 0.3881\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8406 - accuracy: 0.3338 - val_loss: 1.7904 - val_accuracy: 0.3704\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8275 - accuracy: 0.3409 - val_loss: 1.7295 - val_accuracy: 0.3932\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 1.8300 - accuracy: 0.3387 - val_loss: 1.7536 - val_accuracy: 0.3704\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.8291 - accuracy: 0.3416 - val_loss: 1.7392 - val_accuracy: 0.3858\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8232 - accuracy: 0.3431 - val_loss: 1.8307 - val_accuracy: 0.3560\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 1.8183 - accuracy: 0.3461 - val_loss: 1.7496 - val_accuracy: 0.3914\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 12s 240us/step - loss: 2.0205 - accuracy: 0.2821 - val_loss: 1.7495 - val_accuracy: 0.3684\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8392 - accuracy: 0.3357 - val_loss: 1.7177 - val_accuracy: 0.3901\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8133 - accuracy: 0.3434 - val_loss: 1.7055 - val_accuracy: 0.3830\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8232 - accuracy: 0.3407 - val_loss: 1.7217 - val_accuracy: 0.3817\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8250 - accuracy: 0.3419 - val_loss: 1.7702 - val_accuracy: 0.3676\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8213 - accuracy: 0.3414 - val_loss: 1.6935 - val_accuracy: 0.3904\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.8228 - accuracy: 0.3398 - val_loss: 1.7340 - val_accuracy: 0.3777\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8165 - accuracy: 0.3405 - val_loss: 1.6941 - val_accuracy: 0.3966\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7918 - accuracy: 0.3510 - val_loss: 1.6596 - val_accuracy: 0.4103\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7681 - accuracy: 0.3604 - val_loss: 1.6541 - val_accuracy: 0.4111\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7381 - accuracy: 0.3759 - val_loss: 1.6485 - val_accuracy: 0.4026\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7241 - accuracy: 0.3779 - val_loss: 1.8932 - val_accuracy: 0.3252\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7528 - accuracy: 0.3666 - val_loss: 1.6279 - val_accuracy: 0.4220\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7306 - accuracy: 0.3743 - val_loss: 1.6355 - val_accuracy: 0.4234\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.7190 - accuracy: 0.3800 - val_loss: 1.6468 - val_accuracy: 0.4203\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7145 - accuracy: 0.3845 - val_loss: 1.6326 - val_accuracy: 0.4133\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7116 - accuracy: 0.3833 - val_loss: 1.6339 - val_accuracy: 0.4103\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.7093 - accuracy: 0.3850 - val_loss: 1.6398 - val_accuracy: 0.4241\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7195 - accuracy: 0.3790 - val_loss: 1.6442 - val_accuracy: 0.4268\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.7178 - accuracy: 0.3827 - val_loss: 1.6372 - val_accuracy: 0.4160\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7225 - accuracy: 0.3795 - val_loss: 1.6099 - val_accuracy: 0.4365\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.7178 - accuracy: 0.3825 - val_loss: 1.6486 - val_accuracy: 0.4212\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.7212 - accuracy: 0.3815 - val_loss: 1.6211 - val_accuracy: 0.4286\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.7041 - accuracy: 0.3887 - val_loss: 1.5883 - val_accuracy: 0.4424\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.6971 - accuracy: 0.3915 - val_loss: 1.6403 - val_accuracy: 0.4241\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.6946 - accuracy: 0.3926 - val_loss: 1.6484 - val_accuracy: 0.4047\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.6903 - accuracy: 0.3957 - val_loss: 1.5902 - val_accuracy: 0.4356\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.6811 - accuracy: 0.3967 - val_loss: 1.6094 - val_accuracy: 0.4369\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.6772 - accuracy: 0.3987 - val_loss: 1.5785 - val_accuracy: 0.4438\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.6787 - accuracy: 0.3991 - val_loss: 1.5845 - val_accuracy: 0.4484\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.1449 - accuracy: 0.2672 - val_loss: 1.7709 - val_accuracy: 0.3597\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.8286 - accuracy: 0.3489 - val_loss: 1.6748 - val_accuracy: 0.4029\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7366 - accuracy: 0.3781 - val_loss: 1.6743 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6942 - accuracy: 0.3910 - val_loss: 1.5995 - val_accuracy: 0.4293\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6591 - accuracy: 0.4041 - val_loss: 1.5415 - val_accuracy: 0.4543\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6238 - accuracy: 0.4163 - val_loss: 1.5343 - val_accuracy: 0.4477\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6043 - accuracy: 0.4242 - val_loss: 1.5666 - val_accuracy: 0.4331\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6062 - accuracy: 0.4231 - val_loss: 1.5332 - val_accuracy: 0.4476\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5881 - accuracy: 0.4297 - val_loss: 1.5311 - val_accuracy: 0.4467\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5701 - accuracy: 0.4387 - val_loss: 1.4960 - val_accuracy: 0.4631\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5645 - accuracy: 0.4399 - val_loss: 1.5354 - val_accuracy: 0.4510\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5658 - accuracy: 0.4384 - val_loss: 1.5146 - val_accuracy: 0.4579\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5514 - accuracy: 0.4436 - val_loss: 1.5166 - val_accuracy: 0.4619\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5334 - accuracy: 0.4451 - val_loss: 1.4771 - val_accuracy: 0.4721\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5296 - accuracy: 0.4509 - val_loss: 1.4795 - val_accuracy: 0.4719\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.5296 - accuracy: 0.4510 - val_loss: 1.4711 - val_accuracy: 0.4735\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5181 - accuracy: 0.4520 - val_loss: 1.4796 - val_accuracy: 0.4636\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5206 - accuracy: 0.4535 - val_loss: 1.4990 - val_accuracy: 0.4586\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5080 - accuracy: 0.4611 - val_loss: 1.4768 - val_accuracy: 0.4694\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4997 - accuracy: 0.4619 - val_loss: 1.4770 - val_accuracy: 0.4714\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4933 - accuracy: 0.4616 - val_loss: 1.4350 - val_accuracy: 0.4903\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4860 - accuracy: 0.4642 - val_loss: 1.4700 - val_accuracy: 0.4727\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4853 - accuracy: 0.4682 - val_loss: 1.4376 - val_accuracy: 0.4830\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4712 - accuracy: 0.4716 - val_loss: 1.4387 - val_accuracy: 0.4823\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4658 - accuracy: 0.4717 - val_loss: 1.4171 - val_accuracy: 0.4949\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4681 - accuracy: 0.4738 - val_loss: 1.4720 - val_accuracy: 0.4701\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4761 - accuracy: 0.4697 - val_loss: 1.4605 - val_accuracy: 0.4866\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4641 - accuracy: 0.4754 - val_loss: 1.5345 - val_accuracy: 0.4489\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4607 - accuracy: 0.4718 - val_loss: 1.4459 - val_accuracy: 0.4754\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4541 - accuracy: 0.4778 - val_loss: 1.4367 - val_accuracy: 0.4887\n",
      "Experiment with Regulizer = 0.000000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 2.2504 - accuracy: 0.2460 - val_loss: 1.8796 - val_accuracy: 0.3320\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.9025 - accuracy: 0.3271 - val_loss: 1.7050 - val_accuracy: 0.3908\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7895 - accuracy: 0.3613 - val_loss: 1.6307 - val_accuracy: 0.4163\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.7263 - accuracy: 0.3816 - val_loss: 1.5967 - val_accuracy: 0.4285\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6700 - accuracy: 0.4021 - val_loss: 1.5595 - val_accuracy: 0.4447\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6378 - accuracy: 0.4163 - val_loss: 1.5338 - val_accuracy: 0.4474\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6074 - accuracy: 0.4247 - val_loss: 1.5156 - val_accuracy: 0.4547\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5808 - accuracy: 0.4339 - val_loss: 1.5153 - val_accuracy: 0.4594\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5555 - accuracy: 0.4421 - val_loss: 1.4828 - val_accuracy: 0.4658\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5426 - accuracy: 0.4488 - val_loss: 1.4753 - val_accuracy: 0.4709\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5224 - accuracy: 0.4543 - val_loss: 1.4921 - val_accuracy: 0.4650\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5105 - accuracy: 0.4593 - val_loss: 1.5161 - val_accuracy: 0.4532\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5011 - accuracy: 0.4608 - val_loss: 1.4515 - val_accuracy: 0.4797\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4813 - accuracy: 0.4692 - val_loss: 1.4435 - val_accuracy: 0.4805\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4695 - accuracy: 0.4777 - val_loss: 1.4397 - val_accuracy: 0.4861\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4646 - accuracy: 0.4759 - val_loss: 1.4311 - val_accuracy: 0.4838\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4454 - accuracy: 0.4815 - val_loss: 1.4096 - val_accuracy: 0.4977\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4365 - accuracy: 0.4848 - val_loss: 1.4058 - val_accuracy: 0.4973\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4314 - accuracy: 0.4870 - val_loss: 1.4310 - val_accuracy: 0.4862\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4265 - accuracy: 0.4890 - val_loss: 1.4155 - val_accuracy: 0.4965\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4232 - accuracy: 0.4910 - val_loss: 1.4113 - val_accuracy: 0.4918\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4054 - accuracy: 0.4946 - val_loss: 1.3973 - val_accuracy: 0.4963\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3984 - accuracy: 0.4958 - val_loss: 1.3901 - val_accuracy: 0.5034\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3934 - accuracy: 0.5019 - val_loss: 1.3828 - val_accuracy: 0.5036\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3837 - accuracy: 0.5009 - val_loss: 1.4063 - val_accuracy: 0.4985\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3673 - accuracy: 0.5086 - val_loss: 1.4153 - val_accuracy: 0.4941\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3733 - accuracy: 0.5049 - val_loss: 1.4077 - val_accuracy: 0.4938\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3662 - accuracy: 0.5092 - val_loss: 1.3861 - val_accuracy: 0.4993\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3558 - accuracy: 0.5124 - val_loss: 1.3734 - val_accuracy: 0.5113\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3539 - accuracy: 0.5124 - val_loss: 1.3922 - val_accuracy: 0.5011\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for regulizer_ratio in L2_EXP:\n",
    "    for batchsize in BATCH_SIZE:\n",
    "        keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "        print(\"Experiment with Regulizer = %.6f\" % (regulizer_ratio))\n",
    "        model = build_mlp(input_shape=x_train.shape[1:], l2_ratio=regulizer_ratio)\n",
    "        model.summary()\n",
    "        optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "        model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "        model.fit(x_train, y_train, # 訓練資料。\n",
    "                  epochs=EPOCHS,     # 訓練EPOCHS週期，訓練集所有樣本（數據、記錄）參與訓練一次爲一個週期\n",
    "                  batch_size=batchsize,  # 訓練時每個批次的樣本數，訓練樣本數/批次樣本數 = 批次數（每個週期）\n",
    "                  validation_data=(x_test, y_test),  # 驗證資料。\n",
    "                  shuffle=True)   # 每次epochs後，將訓練集打亂順序。\n",
    "\n",
    "        # Collect results\n",
    "        train_loss = model.history.history[\"loss\"]\n",
    "        valid_loss = model.history.history[\"val_loss\"]\n",
    "        train_acc = model.history.history[\"accuracy\"]\n",
    "        valid_acc = model.history.history[\"val_accuracy\"]\n",
    "        \n",
    "        exp_name_tag = \"exp-l2-%s\" % str(regulizer_ratio)\n",
    "        results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                 'valid-loss': valid_loss,\n",
    "                                 'train-accuracy': train_acc,\n",
    "                                 'valid-accuracy': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylim([0, 5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-accuracy'])),results[cond]['train-accuracy'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-accuracy'])),results[cond]['valid-accuracy'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
